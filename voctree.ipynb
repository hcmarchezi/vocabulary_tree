{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vocabulary Tree for Image Descriptors with Binary Descriptors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "This notebook describes how to implement a scalable image search with vocabulary tree.\n",
    "\n",
    "The work is largerly based on the article: **Scalable Recognition with a vocabulary tree**, David Nister and Henrik Stewenius\n",
    "\n",
    "link to paper: http://www-inst.eecs.berkeley.edu/~cs294-6/fa06/papers/nister_stewenius_cvpr2006.pdf\n",
    "\n",
    "However some innovations were applied:\n",
    "* Use of **ORB** as image descriptors instead of patented **SIFT** described in the article \n",
    "* Use of **hamming distance** as distance measure among descritors \n",
    "* Use of **bit-wise average** as opposed to numerical average (since ORB is binary and not numerical as SIFT)\n",
    "* **Flexible clustering algorithm** that makes use of custom distance measure and average as above to work with both binary or numerical image descriptors \n",
    "\n",
    "Results seem to indicate good results with the approach cited above from queries in a small dataset.\n",
    "\n",
    "So far, this notebook provides a relatively simple code in python that implements this algorithm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution \n",
    "The algorithm is composed by several steps expressed as functions in the next subsections.\n",
    "* tree data structure \n",
    "* flexible clustering\n",
    "* tree assembly \n",
    "* tree weight update\n",
    "* tree visit\n",
    "* score calculation\n",
    "* image database visit vector\n",
    "* helper functions to read image database and query image descriptors\n",
    "\n",
    "The following section describes a simple test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install opencv-python\n",
    "# pip install opencv-contrib-python\n",
    "import cv2 \n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Node Data Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    _nodes = []       # list of all created nodes\n",
    "    _total_images = 0 # total number of images\n",
    "    \n",
    "    def __init__(self, root=False):\n",
    "        self._children = {}  # dictionary key(img descriptor) -> value\n",
    "        self._images = set() # set of image ids\n",
    "        if not root:\n",
    "            self._index = len(Node._nodes)\n",
    "            Node._nodes.append(self) # append node to global list of nodes\n",
    "            \n",
    "    @property\n",
    "    def children(self):\n",
    "        return self._children\n",
    "    @children.setter\n",
    "    def children(self, children):\n",
    "        self._children = children\n",
    "        \n",
    "    @property\n",
    "    def images(self):\n",
    "        return self._images\n",
    "    @images.setter\n",
    "    def images(self, images):\n",
    "        self._images = images\n",
    "        \n",
    "    @property\n",
    "    def weight(self):\n",
    "        if len(self.images) > 0:\n",
    "            return np.log(Node._total_images/len(self._images))\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "    @property\n",
    "    def index(self):\n",
    "        return self._index\n",
    "    \n",
    "    @staticmethod\n",
    "    def set_total_images(total_images):\n",
    "        Node._total_images = total_images\n",
    "        \n",
    "    @staticmethod\n",
    "    def nodes():\n",
    "        return Node._nodes\n",
    "    \n",
    "    @staticmethod\n",
    "    def init():\n",
    "        Node._nodes = []\n",
    "\n",
    "\n",
    "        \n",
    "def tree_traversal(node):\n",
    "    print('node.images='+str(node.images) + ' node.children='+str(len(node.children)))\n",
    "    for child_id in node.children:\n",
    "        print('node.descriptor='+str(hash(child_id)))\n",
    "        tree_traversal(node.children[child_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configurable Clustering Algorithms Based on K-Means "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clustering image descriptors\n",
    "def clustering(data, k, dissimilarity, average, stop_criteria=0.1, attempts=3):\n",
    "    centroids = _choose_initial_centroids(data, k)\n",
    "    centroid_labels = None\n",
    "    diff = 100000\n",
    "    \n",
    "    while diff > stop_criteria:\n",
    "        centroid_labels = _find_nearest_centroid(data, centroids, dissimilarity)\n",
    "        new_centroids = _calculate_new_centroids(data, centroid_labels, k, average)\n",
    "        diff = _average_centroids_move(centroids, new_centroids)\n",
    "        centroids = new_centroids\n",
    "    \n",
    "    return centroids, centroid_labels  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def _choose_initial_centroids(data, k):\n",
    "    centroid_idxs = np.random.randint(data.shape[0], size=k)\n",
    "    return data[centroid_idxs]\n",
    "\n",
    "\n",
    "\n",
    "def _find_nearest_centroid(data, centroids, dissimilarity):\n",
    "    centroid_labels = {}\n",
    "    for idx in range(len(centroids)):\n",
    "        centroid_labels[idx] = []\n",
    "        \n",
    "    for item_idx, item in enumerate(data):\n",
    "        min_dist = None\n",
    "        centroid_id = None\n",
    "        for centroid_idx, c in enumerate(centroids):  \n",
    "            distance = dissimilarity(item, c)\n",
    "            if min_dist == None or distance < min_dist:\n",
    "                min_dist = distance\n",
    "                centroid_id = centroid_idx\n",
    "        centroid_labels[centroid_id].append(item_idx)\n",
    "    \n",
    "    return centroid_labels\n",
    "\n",
    "\n",
    "\n",
    "def _calculate_new_centroids(data, centroid_labels, k, average):\n",
    "    centroids = []\n",
    "    \n",
    "    for centroid_idx in centroid_labels:\n",
    "        centroid_data = data[centroid_labels[centroid_idx]]\n",
    "        centroids.append(average(centroid_data))\n",
    "    \n",
    "    return np.array(centroids)\n",
    "\n",
    "\n",
    "\n",
    "def _average_centroids_move(centroids, new_centroids):\n",
    "    return np.sum(np.abs(centroids - new_centroids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assembly Image Descriptor Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assembly_tree(descriptors, k, dissimilarity, average, level):\n",
    "    level -= 1\n",
    "    if level < 0:\n",
    "        return {}\n",
    "\n",
    "    centroids, centroid_labels = clustering(descriptors, k, dissimilarity, average)\n",
    "    children = {}\n",
    "    for centroid_id, centroid in enumerate(centroids):\n",
    "        if len(centroid_labels[centroid_id]) > 0:\n",
    "            node = Node()\n",
    "            centroid_descriptors = np.array(descriptors[centroid_labels[centroid_id]])\n",
    "            node.children = assembly_tree(centroid_descriptors, k, dissimilarity, average, level)\n",
    "            children[centroid.tobytes()] = node\n",
    "            \n",
    "    return children"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updating Tree Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_weights(node, img_idx, arr_descriptors, dissimilarity):\n",
    "    for descriptor in arr_descriptors:\n",
    "        _update_weights_with_descriptor(node, img_idx, descriptor, dissimilarity)\n",
    "\n",
    "# descriptor - query descriptor\n",
    "# arr_descriptors - array of descriptors\n",
    "# return: descritor in arr_descriptors close to descriptor\n",
    "def _nearest_descriptor(descriptor, arr_descriptors, dissimilarity):\n",
    "    min_dist = None\n",
    "    min_descriptor = None\n",
    "    for descriptor_item in arr_descriptors:\n",
    "        distance = dissimilarity(descriptor, descriptor_item)\n",
    "        if min_dist == None or distance < min_dist:\n",
    "            min_dist = distance\n",
    "            min_descriptor = descriptor_item\n",
    "    return min_descriptor\n",
    "\n",
    "\n",
    "def _convert_to_img_descriptor(descriptor_bytes):\n",
    "    return np.frombuffer(descriptor_bytes, dtype=np.uint8)\n",
    "\n",
    "\n",
    "def _update_weights_with_descriptor(node, img_idx, descriptor, dissimilarity):\n",
    "    if len(node.children) > 0:\n",
    "        arr_descriptors = list(map(_convert_to_img_descriptor, node.children.keys()))\n",
    "        nearest_descriptor = _nearest_descriptor(descriptor, arr_descriptors, dissimilarity)\n",
    "        child_node = node.children[nearest_descriptor.tobytes()]\n",
    "        child_node.images.add(img_idx)\n",
    "        _update_weights_with_descriptor(child_node, img_idx, descriptor, dissimilarity)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Node Visiting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visit_tree(root, descriptors, dissimilarity, with_weight=False):\n",
    "    visit_path = np.zeros(len(Node.nodes()))\n",
    "    for descriptor in descriptors:\n",
    "        _descriptor_visit_tree(root, descriptor, dissimilarity, visit_path)\n",
    "        \n",
    "    if with_weight:\n",
    "        for idx, visit in enumerate(visit_path):\n",
    "            visit_path[idx] *= Node.nodes()[idx].weight\n",
    "\n",
    "    return visit_path\n",
    "\n",
    "\n",
    "def _descriptor_visit_tree(node, descriptor, dissimilarity, visit_path):\n",
    "    if node.children == {}:\n",
    "        return visit_path\n",
    "    \n",
    "    arr_descriptors = list(map(_convert_to_img_descriptor, node.children.keys()))\n",
    "    nearest_descriptor = _nearest_descriptor(descriptor, arr_descriptors, dissimilarity)\n",
    "    child_node = node.children[nearest_descriptor.tobytes()]\n",
    "    visit_path[child_node.index] += 1\n",
    "    \n",
    "    return _descriptor_visit_tree(child_node, descriptor, dissimilarity, visit_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query_vector = vector of visits multiplied by weights from query image descriptors\n",
    "# dbimg_vector = vector of visits multiplied by weights from database image descriptors\n",
    "def score_calculation(query_vector, dbimg_vector):\n",
    "    norm_query_vector = query_vector / (np.sqrt(np.sum(np.power(query_vector, 2))))\n",
    "    norm_dbimg_vector = dbimg_vector / (np.sqrt(np.sum(np.power(query_vector, 2))))\n",
    "    diff = np.abs(norm_query_vector - norm_dbimg_vector)\n",
    "    return np.sqrt(np.sum(np.power(diff, 2)))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Matrix for Image Database Visit Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# root:            tree root node\n",
    "#\n",
    "# cvmat_images:    list of B&W cvMat images read from cv2.imread\n",
    "#\n",
    "# dissimilarity:   dissimilarity function to compare 2 image descriptors\n",
    "#\n",
    "# with_weight:     (T/F) should multiply with node weight or just number of visits per node\n",
    "#\n",
    "# descr_extractor: image descriptor extractor (as default ORB)\n",
    "#\n",
    "def dbimg_visit_tree(root, cvmat_images, dissimilarity, with_weight=True, descr_extractor=cv2.ORB_create()):\n",
    "    # list of visit per database image\n",
    "    dbimg_vectors = []\n",
    "    for img in cvmat_images:\n",
    "        keypoints, descriptors = descr_extractor.detectAndCompute(img, None)\n",
    "        \n",
    "        # create visit vector from image and add to list\n",
    "        img_vector = visit_tree(root, descriptors, dissimilarity, with_weight)\n",
    "        dbimg_vectors.append(img_vector)\n",
    "        \n",
    "    return np.array(dbimg_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Function to Read Image Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_images(filenames, black_white=True):\n",
    "    images = []\n",
    "    for filename in filenames:\n",
    "        images.append(read_image(filename, black_white))\n",
    "    \n",
    "    return np.array(images)\n",
    "\n",
    "\n",
    "\n",
    "def read_image(filename, black_white=True):\n",
    "    if black_white:\n",
    "        image = cv2.imread(filename, cv2.IMREAD_GRAYSCALE)\n",
    "    else:\n",
    "        image = cv2.imread(filaneme, cv2.IMREAD_COLOR)\n",
    "        \n",
    "    return image\n",
    "\n",
    "\n",
    "\n",
    "def image_descriptors_map(images, descr_extractor):\n",
    "    img_descriptors = {}\n",
    "    \n",
    "    for idx, image in enumerate(images):\n",
    "        # extract image descriptors\n",
    "        keypoints, descriptors = descr_extractor.detectAndCompute(image, None)\n",
    "        img_descriptors[idx] = []\n",
    "        for descriptor in descriptors:\n",
    "            img_descriptors[idx].append(descriptor)\n",
    "        img_descriptors[idx] = np.array(img_descriptors[idx], dtype=np.uint8)\n",
    "            \n",
    "    return img_descriptors\n",
    "\n",
    "\n",
    "\n",
    "def image_descriptors(image_descriptors_map):\n",
    "    img_descriptors = []\n",
    "    \n",
    "    for img_key in image_descriptors_map:\n",
    "        img_descriptors.extend(image_descriptors_map[img_key])\n",
    "        \n",
    "    return np.array(img_descriptors, dtype=np.uint8)\n",
    "\n",
    "def image_descriptors_from_file(filename, descr_extractor):\n",
    "    img = read_image(filename)\n",
    "    keypoints, descriptors = descr_extractor.detectAndCompute(img, None)\n",
    "    return descriptors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "database filenames\n",
      "==================\n",
      "['./imgdb/shoes-2.png', './imgdb/fruits-1.jpg', './imgdb/fruits-2.jpg', './imgdb/shoes-1.jpg', './imgdb/shoes-3.jpg', './imgdb/helicopter-1.jpg', './imgdb/book-1.jpg', './imgdb/fruits-4.jpg', './imgdb/helicopter-2.jpg', './imgdb/fruit3-3.jpg', './imgdb/shoes-4.png', './imgdb/shoes-5.jpg', './imgdb/helicopter-3.jpg', './imgdb/helicopter-4.jpg']\n",
      "\n",
      "query filenames\n",
      "===============\n",
      "['./query/shoes.png', './query/helicopter.jpg', './query/fruits-4.jpg', './query/book.jpg', './query/fruits.jpg']\n"
     ]
    }
   ],
   "source": [
    "filenames = list([ './imgdb/' + filename for filename in os.listdir('./imgdb/') ])\n",
    "print('database filenames')\n",
    "print('==================')\n",
    "print(str(filenames))\n",
    "print()\n",
    "\n",
    "query_files = list([ './query/' + filename for filename in os.listdir('./query') ])\n",
    "print('query filenames')\n",
    "print('===============')\n",
    "print(str(query_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test1: ORB / hamming distance / bit-wise average\n",
    "\n",
    "Next block below defines the parameters for this experiments.\n",
    "* ORB as image descriptor\n",
    "* hamming as distance measure\n",
    "* bit-wise as average strategy\n",
    "* 6 clusters (also means that the vocabulary tree node will have 6 children\n",
    "* 5 max vertical levels for the tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-condition: uint8 arrays - hamming distance\n",
    "def orb_dissimilarity(elem1, elem2):\n",
    "    return cv2.norm(elem1, elem2, cv2.NORM_HAMMING) \n",
    "\n",
    "# pre-condition: uint8 arrays - bit-wise average\n",
    "def orb_average(data):\n",
    "    bit_array = np.unpackbits(data, axis=1)\n",
    "    avg_array = np.mean(bit_array, axis=0)\n",
    "    avg_array = np.round(avg_array).astype(np.uint8)\n",
    "    avg_data = np.packbits(avg_array)\n",
    "    return avg_data\n",
    "\n",
    "# Set number of images\n",
    "Node.set_total_images(len(filenames))\n",
    "\n",
    "# Set image descriptor extractor\n",
    "orb_extractor = cv2.ORB_create()\n",
    "\n",
    "# Number of clusters\n",
    "clusters = 6\n",
    "\n",
    "# Tree max level\n",
    "max_level = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of images=14\n",
      "number of descriptors=7000\n"
     ]
    }
   ],
   "source": [
    "images = read_images(filenames, black_white=True)\n",
    "db_descriptors_map = image_descriptors_map(images, descr_extractor=orb_extractor)\n",
    "db_descriptors = image_descriptors(db_descriptors_map)\n",
    "print('number of images='+str(images.shape[0]))\n",
    "print('number of descriptors='+str(db_descriptors.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hcmarchezi/anaconda3/lib/python3.6/site-packages/numpy/core/fromnumeric.py:2957: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/home/hcmarchezi/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:73: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret, rcount, out=ret, casting='unsafe', subok=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of nodes:5234\n"
     ]
    }
   ],
   "source": [
    "Node.init()\n",
    "root = Node(root=True)\n",
    "root.children = assembly_tree(descriptors=db_descriptors, k=clusters, dissimilarity=orb_dissimilarity, average=orb_average, level=max_level)\n",
    "print('number of nodes:' + str(len(Node.nodes())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for imgkey in db_descriptors_map:\n",
    "    update_weights(root, imgkey, db_descriptors_map[imgkey], dissimilarity=orb_dissimilarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "database image vector size = (14, 5234)\n"
     ]
    }
   ],
   "source": [
    "db_visit_matrix = dbimg_visit_tree(root, images, dissimilarity=orb_dissimilarity, with_weight=True, descr_extractor=orb_extractor)\n",
    "print('database image vector size = '+str(db_visit_matrix.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "query_file: ./query/shoes.png\n",
      "file=./imgdb/helicopter-1.jpg score=1.152057764653891\n",
      "file=./imgdb/shoes-5.jpg score=1.1866744356691463\n",
      "file=./imgdb/fruits-1.jpg score=1.1966080585658625\n",
      "file=./imgdb/helicopter-4.jpg score=1.2149070240666813\n",
      "file=./imgdb/shoes-3.jpg score=1.2175587827364887\n",
      "file=./imgdb/helicopter-2.jpg score=1.22168300260521\n",
      "file=./imgdb/fruits-2.jpg score=1.225608048466288\n",
      "file=./imgdb/fruits-4.jpg score=1.2290480184701178\n",
      "file=./imgdb/book-1.jpg score=1.2324059293944285\n",
      "file=./imgdb/helicopter-3.jpg score=1.2744814504360338\n",
      "file=./imgdb/shoes-4.png score=1.311162413678284\n",
      "file=./imgdb/fruit3-3.jpg score=1.314323094218643\n",
      "file=./imgdb/shoes-1.jpg score=1.3602204086762604\n",
      "file=./imgdb/shoes-2.png score=1.7676234359126441\n",
      "--------------------------------------\n",
      "query_file: ./query/helicopter.jpg\n",
      "file=./imgdb/helicopter-2.jpg score=1.1407128895309477\n",
      "file=./imgdb/helicopter-1.jpg score=1.2073783661341377\n",
      "file=./imgdb/shoes-5.jpg score=1.2087691254723\n",
      "file=./imgdb/helicopter-4.jpg score=1.2236714926842234\n",
      "file=./imgdb/fruits-4.jpg score=1.2641085274988013\n",
      "file=./imgdb/fruits-1.jpg score=1.2664907506643317\n",
      "file=./imgdb/fruits-2.jpg score=1.2756957809225964\n",
      "file=./imgdb/book-1.jpg score=1.2789378354245213\n",
      "file=./imgdb/shoes-3.jpg score=1.2826742923476226\n",
      "file=./imgdb/helicopter-3.jpg score=1.3249802064351803\n",
      "file=./imgdb/fruit3-3.jpg score=1.3632237168429215\n",
      "file=./imgdb/shoes-1.jpg score=1.4287156148682576\n",
      "file=./imgdb/shoes-4.png score=1.4428215662317063\n",
      "file=./imgdb/shoes-2.png score=1.8603449246499255\n",
      "--------------------------------------\n",
      "query_file: ./query/fruits-4.jpg\n",
      "file=./imgdb/fruits-4.jpg score=0.0\n",
      "file=./imgdb/fruits-2.jpg score=1.2842348509833417\n",
      "file=./imgdb/shoes-5.jpg score=1.307539642601198\n",
      "file=./imgdb/helicopter-4.jpg score=1.3200299925452454\n",
      "file=./imgdb/helicopter-1.jpg score=1.3203880419883929\n",
      "file=./imgdb/fruits-1.jpg score=1.3208654848062535\n",
      "file=./imgdb/helicopter-3.jpg score=1.3887951029664913\n",
      "file=./imgdb/helicopter-2.jpg score=1.3986009380252176\n",
      "file=./imgdb/shoes-3.jpg score=1.4002840515903747\n",
      "file=./imgdb/fruit3-3.jpg score=1.401405134504946\n",
      "file=./imgdb/book-1.jpg score=1.4203934386160189\n",
      "file=./imgdb/shoes-1.jpg score=1.4867930383252397\n",
      "file=./imgdb/shoes-4.png score=1.531907648918792\n",
      "file=./imgdb/shoes-2.png score=2.00842998628565\n",
      "--------------------------------------\n",
      "query_file: ./query/book.jpg\n",
      "file=./imgdb/book-1.jpg score=1.3712989859816636\n",
      "file=./imgdb/shoes-5.jpg score=1.3816829960234875\n",
      "file=./imgdb/helicopter-1.jpg score=1.412081427560964\n",
      "file=./imgdb/fruits-2.jpg score=1.4235923595234816\n",
      "file=./imgdb/helicopter-4.jpg score=1.4500643457530897\n",
      "file=./imgdb/fruits-4.jpg score=1.4520774832336591\n",
      "file=./imgdb/fruits-1.jpg score=1.4563526946031646\n",
      "file=./imgdb/helicopter-2.jpg score=1.5020402868154208\n",
      "file=./imgdb/shoes-3.jpg score=1.5030444401297278\n",
      "file=./imgdb/helicopter-3.jpg score=1.5425863815940657\n",
      "file=./imgdb/fruit3-3.jpg score=1.5450432600122366\n",
      "file=./imgdb/shoes-1.jpg score=1.6510462997651416\n",
      "file=./imgdb/shoes-4.png score=1.7156337425353212\n",
      "file=./imgdb/shoes-2.png score=2.2998490756881806\n",
      "--------------------------------------\n",
      "query_file: ./query/fruits.jpg\n",
      "file=./imgdb/fruits-2.jpg score=1.245150797734923\n",
      "file=./imgdb/fruits-4.jpg score=1.2564129556219754\n",
      "file=./imgdb/fruits-1.jpg score=1.270580570032952\n",
      "file=./imgdb/shoes-5.jpg score=1.2934823488005365\n",
      "file=./imgdb/helicopter-4.jpg score=1.2959593444346094\n",
      "file=./imgdb/helicopter-1.jpg score=1.298100096960604\n",
      "file=./imgdb/helicopter-2.jpg score=1.375257926020723\n",
      "file=./imgdb/shoes-3.jpg score=1.3752789790605027\n",
      "file=./imgdb/fruit3-3.jpg score=1.395635329510066\n",
      "file=./imgdb/book-1.jpg score=1.4157265263502294\n",
      "file=./imgdb/helicopter-3.jpg score=1.4177358404984703\n",
      "file=./imgdb/shoes-1.jpg score=1.476788847630549\n",
      "file=./imgdb/shoes-4.png score=1.5633375196025456\n",
      "file=./imgdb/shoes-2.png score=2.064222556699544\n"
     ]
    }
   ],
   "source": [
    "for query_file in query_files: \n",
    "    query_descriptors = image_descriptors_from_file(query_file, descr_extractor=orb_extractor)\n",
    "    query_vector = visit_tree(root, descriptors=query_descriptors, dissimilarity=orb_dissimilarity, with_weight=True)\n",
    "\n",
    "    scores = {}\n",
    "    for idx, db_item_vector in enumerate(db_visit_matrix):\n",
    "        scores[score_calculation(query_vector, db_item_vector)] = filenames[idx]\n",
    "\n",
    "    print('--------------------------------------')\n",
    "    print('query_file: ' + str(query_file))\n",
    "    for key in sorted(scores.keys(), reverse=False):\n",
    "        print('file='+str(scores[key]) + ' score=' + str(key))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 1 Conclusions\n",
    "Vocabulary tree seems to have work as expected.\n",
    "* when searched with database image (fruits-4) the nearest result had distance 0 as expected since there is an identical image in the database\n",
    "* when searched with very similar image (book) the expected answer (book-1) was returned\n",
    "* when searched with semantically similar images there were good results for (fruits) and (helicopter) but not so good for (shoes).\n",
    "\n",
    "Perhaps using a ground truth by actually comparing each descriptor from database with query could help elucidate if this results with similar images are happening due a limitation in the image descriptor itself."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
